#!/usr/bin/env python3
"""
SOC-AI-Agent â€” Automated Screenshot Capture

Submits all 10 sample alerts through the backend API, captures the live
investigation stream, and screenshots every key page in the dashboard.

Usage:
    python take_screenshots.py            # headless (for CI)
    python take_screenshots.py --visible  # watch in real-time

Prerequisites:
    pip install -r requirements_screenshots.txt
    playwright install chromium
    docker compose up --build   # SOC-AI-Agent must be running
"""

import argparse
import asyncio
import sys
from pathlib import Path

try:
    import aiohttp
except ImportError:
    sys.exit("Missing dependency.  Run:  pip install aiohttp")

try:
    from playwright.async_api import async_playwright, TimeoutError as PwTimeout
except ImportError:
    sys.exit(
        "Missing dependency.  Run:\n"
        "  pip install playwright\n"
        "  playwright install chromium"
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Configuration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_DIR    = Path(__file__).resolve().parent
FRONT       = "http://localhost:3000"
SS_DIR      = BASE_DIR / "demo_screenshots"
SAMPLE_DIR  = BASE_DIR / "sample_alerts"
VIEWPORT    = {"width": 1920, "height": 1080}
INV_TIMEOUT = 300   # max seconds to wait per investigation
POLL_SEC    = 3     # polling interval

# Submission order â€” mimikatz saved for LAST so we can capture its live stream
ALERTS = [
    ("sysmon_powershell_encoded.xml", "auto"),
    ("brute_force_auth.log",         "auto"),
    ("phishing_email.eml",           "auto"),
    ("suspicious_dns.log",           "auto"),
    ("ransomware_sysmon.xml",        "auto"),
    ("lateral_movement.xml",         "auto"),
    ("c2_beacon.log",                "auto"),
    ("data_exfiltration.log",        "auto"),
    ("insider_threat.log",           "auto"),
    ("sysmon_mimikatz.xml",          "auto"),   # 10th â€” live screenshot target
]

n_shots = 0          # running total of screenshots saved


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def p(msg=""):
    """Print with immediate flush."""
    print(msg, flush=True)


# â”€â”€ Service health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def services_healthy() -> bool:
    """Return True when both frontend and backend respond."""
    timeout = aiohttp.ClientTimeout(total=8)
    async with aiohttp.ClientSession(timeout=timeout) as s:
        # Frontend
        try:
            async with s.get(FRONT) as r:
                if r.status != 200:
                    p(f"  âœ— Frontend returned HTTP {r.status}")
                    return False
            p(f"  âœ“ Frontend OK  ({FRONT})")
        except Exception as exc:
            p(f"  âœ— Frontend unreachable at {FRONT}: {exc}")
            p("    â†’ Run: docker compose up --build")
            return False

        # Backend (through the nginx proxy)
        try:
            async with s.get(f"{FRONT}/api/health") as r:
                d = await r.json()
                p(f"  âœ“ Backend  OK  ({d.get('service', '?')} v{d.get('version', '?')})")
        except Exception as exc:
            p(f"  âœ— Backend API unreachable: {exc}")
            p("    â†’ Run: docker compose up --build")
            return False
    return True


# â”€â”€ API submit / poll â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def api_submit(session: aiohttp.ClientSession, content: str,
                     alert_type: str = "auto") -> str | None:
    """POST alert via backend Form API.  Returns alert_id or None."""
    fd = aiohttp.FormData()
    fd.add_field("content", content)
    fd.add_field("alert_type", alert_type)
    try:
        async with session.post(f"{FRONT}/api/investigate", data=fd) as r:
            if r.status in (200, 201, 202):
                return (await r.json()).get("alert_id")
            p(f"      âš  API returned {r.status}: {(await r.text())[:120]}")
    except Exception as exc:
        p(f"      âš  API error: {exc}")
    return None


async def api_poll(session: aiohttp.ClientSession, alert_id: str,
                   quiet: bool = False) -> dict | None:
    """Poll GET /api/investigations/{id} until status == complete.
    Returns the full result dict, or None on timeout."""
    for tick in range(INV_TIMEOUT // POLL_SEC):
        try:
            async with session.get(
                f"{FRONT}/api/investigations/{alert_id}"
            ) as r:
                if r.status == 200:
                    data = await r.json()
                    if data.get("status") == "complete":
                        if not quiet:
                            v = data.get("verdict", "?")
                            c = data.get("confidence")
                            cpct = (f"{c:.1f}%"
                                    if isinstance(c, (int, float)) and c is not None
                                    else "?")
                            p(f"      âœ“ {v} ({cpct} confidence)")
                        return data
                # 404 = record not created yet; keep waiting
        except Exception:
            pass
        await asyncio.sleep(POLL_SEC)
    if not quiet:
        p(f"      âš  timed out after {INV_TIMEOUT}s")
    return None


# â”€â”€ Screenshot wrapper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def snap(page, filename: str, label: str) -> bool:
    """Take a viewport screenshot.  Returns True on success."""
    global n_shots
    path = str(SS_DIR / filename)
    try:
        await page.screenshot(path=path, full_page=False)
        n_shots += 1
        p(f"  ğŸ“¸  {label}  â†’  {filename}")
        return True
    except Exception as exc:
        p(f"  âœ—  {label}: {exc}")
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Main automation flow
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run(*, headless: bool = True):
    p()
    p("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    p("â•‘   SOC-AI-Agent  â€”  Automated Screenshot Capture           â•‘")
    p("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    p()

    # â”€â”€ Preflight checks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    p("[*] Checking services...")
    if not await services_healthy():
        sys.exit(1)

    missing = [fn for fn, _ in ALERTS if not (SAMPLE_DIR / fn).exists()]
    if missing:
        for m in missing:
            p(f"  âœ— Missing sample alert: {SAMPLE_DIR / m}")
        sys.exit(1)
    p(f"  âœ“ All {len(ALERTS)} sample alerts found")
    p()

    SS_DIR.mkdir(exist_ok=True)
    last_alert_id: str | None = None

    async with async_playwright() as pw:
        browser = await pw.chromium.launch(
            headless=headless,
            args=["--disable-gpu", "--no-sandbox"],
        )
        ctx = await browser.new_context(
            viewport=VIEWPORT,
            device_scale_factor=1,
            color_scheme="dark",
        )
        page = await ctx.new_page()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #  Phase 1 â€” Screenshot the empty Alert Submit page
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        p("â”" * 58)
        p("  Phase 1 â€” Alert Submit Page")
        p("â”" * 58)

        await page.goto(f"{FRONT}/investigate", wait_until="networkidle")
        # Let CSS animations / transitions settle
        await page.wait_for_timeout(2000)
        await snap(page, "10_alert_submit.png", "Alert Submit (empty)")
        p()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #  Phase 2 â€” Submit all 10 sample alerts
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        p("â”" * 58)
        p("  Phase 2 â€” Submitting 10 Sample Alerts")
        p("â”" * 58)

        api_timeout = aiohttp.ClientTimeout(total=30)
        async with aiohttp.ClientSession(timeout=api_timeout) as ses:

            for idx, (filename, atype) in enumerate(ALERTS, 1):
                content = (SAMPLE_DIR / filename).read_text(
                    encoding="utf-8", errors="replace"
                )
                is_last = (idx == len(ALERTS))

                p(f"\n  [{idx:>2}/{len(ALERTS)}] {filename}")

                # Submit via backend Form API
                alert_id = await api_submit(ses, content, atype)
                if not alert_id:
                    p("        âœ— Submission failed â€” skipping")
                    continue

                # â”€â”€ Alert 10 (mimikatz, last) â€” capture live stream â”€â”€
                if is_last:
                    last_alert_id = alert_id
                    p(f"        â†’ Navigating to live investigation page...")

                    # Navigate to the LiveInvestigation view immediately
                    await page.goto(
                        f"{FRONT}/investigate/{alert_id}",
                        wait_until="domcontentloaded",
                    )

                    # Wait for the streaming UI to begin showing stages
                    try:
                        await page.wait_for_function(
                            """() => {
                                const t = document.body.innerText;
                                return t.includes('CONNECTED')
                                    || t.includes('Parsing Alert')
                                    || t.includes('PROCESSING')
                                    || t.includes('Investigation Progress');
                            }""",
                            timeout=15000,
                        )
                    except PwTimeout:
                        # Page may show waiting state; screenshot it anyway
                        pass

                    # Give a few seconds for stages to stream in
                    await page.wait_for_timeout(4000)

                    await snap(
                        page,
                        "01_live_investigation_streaming.png",
                        "Live investigation (streaming)",
                    )

                    # Now wait for the verdict / download buttons
                    p("        Waiting for verdict...")
                    try:
                        await page.wait_for_function(
                            """() => {
                                const t = document.body.innerText;
                                return t.includes('Download HTML Report')
                                    || t.includes('View Details');
                            }""",
                            timeout=INV_TIMEOUT * 1000,
                        )
                    except PwTimeout:
                        # Fall back: poll the API and reload the page
                        p("        âš  Browser-side wait timed out â€” polling API...")
                        result = await api_poll(ses, alert_id, quiet=True)
                        if result:
                            v = result.get("verdict", "?")
                            c = result.get("confidence")
                            cpct = (f"{c:.1f}%"
                                    if isinstance(c, (int, float)) and c is not None
                                    else "?")
                            p(f"        âœ“ API says: {v} ({cpct})")
                        # Reload so the page reflects completion
                        await page.reload(wait_until="networkidle")

                    await page.wait_for_timeout(2000)
                    await snap(
                        page,
                        "02_investigation_verdict.png",
                        "Investigation verdict",
                    )

                # â”€â”€ Alerts 1-9 â€” just wait for completion â”€â”€â”€â”€â”€â”€â”€â”€
                else:
                    await api_poll(ses, alert_id)

        p(f"\n  âœ“ All {len(ALERTS)} alerts submitted.")
        p()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #  Phase 3 â€” Dashboard Screenshots
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        p("â”" * 58)
        p("  Phase 3 â€” Dashboard Screenshots")
        p("â”" * 58)
        p()

        # â”€â”€ 3. Dashboard Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        await page.goto(FRONT, wait_until="networkidle")
        # Wait for stat cards or chart SVGs to appear
        try:
            await page.wait_for_function(
                """() => {
                    return document.querySelectorAll('.stat-card').length > 0
                        || document.querySelectorAll('svg').length > 2;
                }""",
                timeout=10000,
            )
        except PwTimeout:
            pass
        await page.wait_for_timeout(2500)
        await snap(page, "03_dashboard_overview.png", "Dashboard overview")

        # Scroll to bottom for charts / tables below the fold
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        await page.wait_for_timeout(1500)
        await snap(page, "03b_dashboard_bottom.png", "Dashboard (scrolled)")
        await page.evaluate("window.scrollTo(0, 0)")
        p()

        # â”€â”€ 4. MITRE ATT&CK Heatmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        await page.goto(f"{FRONT}/attack-map", wait_until="networkidle")
        await page.wait_for_timeout(3000)
        await snap(page, "04_mitre_attack_heatmap.png", "MITRE ATT&CK Heatmap")
        p()

        # â”€â”€ 5. IOC Database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        await page.goto(f"{FRONT}/iocs", wait_until="networkidle")
        try:
            await page.wait_for_function(
                "() => document.querySelectorAll('tbody tr').length > 0",
                timeout=10000,
            )
        except PwTimeout:
            pass
        await page.wait_for_timeout(1500)
        await snap(page, "05_ioc_database.png", "IOC Database")
        p()

        # â”€â”€ 6. Investigation History â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        await page.goto(f"{FRONT}/history", wait_until="networkidle")
        try:
            await page.wait_for_function(
                "() => document.querySelectorAll('tbody tr').length > 0",
                timeout=10000,
            )
        except PwTimeout:
            pass
        await page.wait_for_timeout(1500)
        await snap(page, "06_investigation_history.png", "Investigation History")
        p()

        # â”€â”€ 7. Investigation Detail (Mimikatz) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if last_alert_id:
            await page.goto(
                f"{FRONT}/investigation/{last_alert_id}",
                wait_until="networkidle",
            )
            await page.wait_for_timeout(3000)
            await snap(
                page,
                "07_investigation_detail_top.png",
                "Investigation Detail (top)",
            )

            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await page.wait_for_timeout(1200)
            await snap(
                page,
                "07b_investigation_detail_bottom.png",
                "Investigation Detail (bottom)",
            )
        else:
            p("  âš  No last_alert_id â€” skipping detail screenshots")
        p()

        # â”€â”€ 8. HTML Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if last_alert_id:
            await page.goto(
                f"{FRONT}/api/reports/{last_alert_id}/html",
                wait_until="networkidle",
            )
            await page.wait_for_timeout(2000)
            await snap(page, "08_html_report.png", "HTML Report")
        else:
            p("  âš  No last_alert_id â€” skipping HTML report screenshot")
        p()

        # â”€â”€ 9. PDF Report (screenshot the HTML report scrolled) â”€â”€
        if last_alert_id:
            # The HTML report is still loaded from step 8; scroll down
            await page.evaluate("window.scrollTo(0, 800)")
            await page.wait_for_timeout(1000)
            await snap(page, "09_pdf_report.png", "Report (scrolled section)")
        p()

        # â”€â”€ 11. Threat Analytics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        await page.goto(f"{FRONT}/analytics", wait_until="networkidle")
        # Analytics may use mock data; give charts time to render
        await page.wait_for_timeout(3500)
        await snap(page, "11_threat_analytics.png", "Threat Analytics")
        p()

        await browser.close()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  Phase 4 â€” Summary & README Markdown
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    p("â”" * 58)
    p("  Phase 4 â€” Results")
    p("â”" * 58)
    p()
    p(f"  âœ… {n_shots} screenshots saved to {SS_DIR.relative_to(BASE_DIR)}/")
    p()

    # List files saved
    for f in sorted(SS_DIR.glob("*.png")):
        size_kb = f.stat().st_size / 1024
        p(f"      {f.name:45s} {size_kb:>7.1f} KB")
    p()

    # README-ready markdown snippet
    markdown = """\
## Screenshots

### Dashboard
![Dashboard Overview](demo_screenshots/03_dashboard_overview.png)

### Live Investigation Stream
![Live Investigation](demo_screenshots/01_live_investigation_streaming.png)

### Investigation Verdict
![Verdict](demo_screenshots/02_investigation_verdict.png)

### MITRE ATT&CK Heatmap
![ATT&CK Heatmap](demo_screenshots/04_mitre_attack_heatmap.png)

### IOC Database
![IOC Database](demo_screenshots/05_ioc_database.png)

### Investigation History
![Investigation History](demo_screenshots/06_investigation_history.png)

### Investigation Detail
![Investigation Detail](demo_screenshots/07_investigation_detail_top.png)
![Investigation Detail - Continued](demo_screenshots/07b_investigation_detail_bottom.png)

### Generated Incident Report
![HTML Report](demo_screenshots/08_html_report.png)

### Alert Submission
![Alert Submit](demo_screenshots/10_alert_submit.png)

### Threat Analytics
![Threat Analytics](demo_screenshots/11_threat_analytics.png)
"""
    p("â”€â”€ README Markdown Snippet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(markdown)
    p("â”€â”€ End â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    p()
    p("To run:")
    p("  pip install -r requirements_screenshots.txt")
    p("  playwright install chromium")
    p("  python take_screenshots.py          # headless mode")
    p("  python take_screenshots.py --visible  # watch it in real-time")
    p()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Entry point
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    ap = argparse.ArgumentParser(
        description="SOC-AI-Agent â€” Automated screenshot capture"
    )
    ap.add_argument(
        "--visible",
        action="store_true",
        help="Show the browser window (headless=False)",
    )
    args = ap.parse_args()
    asyncio.run(run(headless=not args.visible))


if __name__ == "__main__":
    main()
